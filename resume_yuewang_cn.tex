% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode
% !Mode:: "TeX:UTF-8"

\documentclass{resume}
\usepackage{zh_CN-Adobefonts_external} % Simplified Chinese Support using external fonts (./fonts/zh_CN-Adobe/)
% \usepackage{NotoSansSC_external}
% \usepackage{NotoSerifCJKsc_external}
% \usepackage{zh_CN-Adobefonts_internal} % Simplified Chinese Support using system fonts
\usepackage{linespacing_fix} % disable extra space before next section
\usepackage{cite}
\usepackage{hyperref}
% \usepackage{fontawesome5}

\begin{document}
\pagenumbering{gobble} % suppress displaying page number

\name{汪跃}

\basicInfo{
  \email{yuewang\_yw@foxmail.com} \ 
  \phone{(+86) 18810295643}  }
\centerline{\faMap 丹棱街5号， 2号楼， 北京市海淀区， 100080， 中国}
%  \linkedin[billryan8]{https://www.linkedin.com/in/billryan8}}
 
\section{\faGraduationCap\  教育背景}
\datedsubsection{\textbf{概率论与数理统计, 北京交通大学}， 直博生 }{2015 -- 2020(预计)}
%\textit{在读博士研究生}\ 信息与通信工程, 预计 2016 年 3 月毕业
导师： 马志明； 院士； 中国科学院数学与系统科学研究院
\datedsubsection{\textbf{信息与计算科学, 北京交通大学}，本科生}{2011 -- 2015}
{综合绩点: 92.03/100, 排名：1/98}

\section{\faUsers\ 研究兴趣}
 

\datedsubsection{\textbf{强化学习}  } {}
策略评估问题的算法设计与效率分析； 策略优化问题中的算法设计及理论分析； 深度强化学习 

\datedsubsection{\textbf{随机优化算法}  } {}
分布式优化算法的泛化能力分析； 深度神经网络中的优化算法设计与分析
 

%\datedsubsection{\textbf{\LaTeX\ 简历模板}}{2015 年5月 -- 至今}
%\role{\LaTeX, Python}{个人项目}
%\begin{onehalfspacing}
%优雅的 \LaTeX\ 简历模板, https://github.com/billryan/resume
%\begin{itemize}
%  \item 容易定制和扩展
%  \item 完善的 Unicode 字体支持，使用 \XeLaTeX\ 编译
%  \item 支持 FontAwesome 4.5.0
%\end{itemize}
%\end{onehalfspacing}

% Reference Test
%\datedsubsection{\textbf{Paper Title\cite{zaharia2012resilient}}}{May. 2015}
%An xxx optimized for xxx\cite{verma2015large}
%\begin{itemize}
%  \item main contribution
%\end{itemize}
\section{\faCogs\ 科研经历}
 


\datedsubsection{\textbf{1. 强化学习}, 微软亚洲研究院}{2017 -- 2019}
强化学习问题按照目标的不同可以分为策略评估问题与策略优化问题。考虑到强化学习问题数据收集代价很高，在理论上清楚理解算法的表现，有助于我们理解算法的各个模块，进而更好的改进算法。

a. \textbf{（数据非独立同分布情形下，给出了一类基于梯度的策略评估算法的收敛速率分析）}  
\begin{itemize}
  \item 策略评估问题旨在快速准确地估计特定策略下所有状态的预期收益。 在强化学习问题中，数据是智能体逐步与环境交互产生的，状态之间的转移满足马尔可夫性，因此数据天然不是独立同分布的。只有极少数工作在数据独立同分布的假设下给出了弱的理论分析。  

  \item  一个很关键也很有意义的问题是： 在数据非独立同分布的情况下，策略评估算法是否还能收敛， 收敛速率如何受到数据非独立同分布性质的影响？
  
  \item 通过引入混合时间这一工具（直观理解成马氏链收敛到平稳分布的速度），我们刻画了数据非独立同分布的程度，证明了更一般的鞍点问题的收敛速率，进而给出了一类基于梯度的策略评估算法在on-poliy 和off-policy 的情况下的收敛速率分析。我们证明了策略评估算法在数据非独立同分布的情况下依然收敛，并且混合时间越大，收敛速率会变得越慢。
\end{itemize}


\faHandORight 在这个工作中，我负责了问题的提出与理解， 理论分析与证明，实验的设计与代码实现。

b. \textbf{（系统研究了基于最优贝尔曼方程的Q-learning算法的收敛速率与各个影响因素的关系，提出了有理论保证的迁移强化学习算法）} 
\begin{itemize}
  \item 策略优化问题旨在设计高效算法找到最优的策略。强化学习与监督学习最大的区别在于其属于一类弱监督学习问题，即所有的数据都只有一小部分标签的信息，而没有完整的标签。
  \item 贝尔曼方程为强化学习的求解提供了工具与理论保证， 在贴近实际的假设下，基于贝尔曼方程的时间差分算法（如Q-learning）的收敛速率以及对其各种影响因素的分析是一个非常重要的问题。
  \item 我们细致研究了时间差分算法的收敛速率，理论上证明了收敛速率与error ratio呈指数关系。 基于理论发现，我们提出了一个有收敛速率保证的迁移强化学习算法（Target Transfer Q-Learning），并设计了实验验证了我们的理论结果。
\end{itemize}

\faHandORight 在这个工作中，我负责了问题的提出与理解， 理论分析与证明，实验的设计与代码实现。

% \datedsubsection{\textbf{强化学习中的策略优化问题}, 微软亚洲研究院}{2018 -- 2019}

\datedsubsection{\textbf{2.深度神经网络中的优化问题}, 微软亚洲研究院}{2018 -- 2019}
a.\textbf{（为多种常用的网络结构设计新的非冗余参数空间，并且高效实现了新空间上的优化算法）} 

\begin{itemize}
  \item 深度神经网络复杂的表现能力使其在很多实际问题中表现出非常好的拟合能力。%常用的随机优化算法(SGD 等)往往与神经网络的结构无关，只是沿着负梯度的方向在神经网络的参数空间更新神经网络的参数。
  \item 然而以ReLU作为激活函数的多种常用神经网络结构却天然存在正伸缩不变性。即存在无穷多参数不同的神经网络互相等价。这就使得优化算法在等价的神经网络上表现差别很大。
  \item 通过考虑神经网络的结构信息，我们为  等宽/不等宽/带跨层连接 的 全连接网络和CNN 网络， RNN，Attention 等现代常用的多种深度神经网络设计了新的参数空间（PSI空间），并且设计实验验了在新空间做优化的有效性。新的算法在图像和文本等多个任务上取得了很好的结果。
\end{itemize} 
    
 \faHandORight 在这个工作中，我负责在多种网络结构之下证明新的参数空间的存在，设计算法来构造PSI空间, 高效率实现在多种网络结构中PSI空间上的优化算法。相关代码成果形成了一套codebase 和pipline为组内其他相关工作提供帮助。

   
 \datedsubsection{\textbf{3.随机优化算法的理论性质分析}, 微软亚洲研究院}{2016 -- 2017}

 a. \textbf{（利用随机优化算法的stability，分析算法的泛化能力）} 利用优化算法来求解一个机器学习问题的泛化误差，通常可以分解成优化误差，估计误差和近似误差三部分。我们利用算法的稳定性这一指标，对算法的泛化误差进行刻画，得到了相比于之前更紧的结论。 \\
%  优化误差受到算法的收敛速率的影响，估计误差反映了经验样本和总体分布之间的差距， 近似误差由函数空间表达能力所限制。
 b. \textbf{（在实际数据处理中采用shuffle的过程而非随机采样的情况下，讨论分布式优化算法的收敛性）} 在实际问题中考虑到时间代价，数据往往不是独立同分布采样，而是随机打乱后训练一遍， 如此循环。我们在分布式优化中， 分析了充分与不充分打乱所有数据对最后优化算法的收敛速率的影响。\\
 \faHandORight 在这两个工作中，我参与论文证明思路的讨论， 负责论文实验部分的代码实现与结果可视化。

\section{\faBook\ 论文}

 \begin{enumerate}
 	\item \textbf{Wang Yue}, Wei Chen, Yuting Liu, Zhi-Ming Ma and Tie-Yan Liu. “Finite Sample Analysis of the GTD Policy Evaluation Algorithms in Markov Setting.” Advances in Neural Information Processing Systems. 2017. 
 	
 	\item Meng Qi, \textbf{Yue Wang}, Wei Chen, Taifeng Wang, Zhi-Ming Ma and Tie-Yan Liu. “Generalization Error Bounds for Optimization Algorithms via Stability.” Thirty-First AAAI Conference on Artificial Intelligence. 2017.
  	
 	\item Meng Qi, Wei Chen, \textbf{Yue Wang}, Zhi-Ming Ma and Tie-Yan Liu. “Convergence analysis of distributed stochastic gradient descent with shuffling.” Neurocomputing 337 (2017): 46-57.
 	
 	\item Liang Ma, Edmund T Rolls, Xiuqin Liu, Yuting Liu, Zeyu Jiao, \textbf{Yue Wang}, Weikang Gong, Zhi-Ming Ma, Fuzhou Gong, Lin Wan, "Multi-scale analysis of schizophrenia risk genes, brain structure, and clinical symptoms reveals integrative clues for subtyping schizophrenia   patients." Journal of Molecular Cell Biology
 	
 	 	
 	\item \textbf{Wang Yue}, Qi Meng, Wei Chen, Yuting Liu, Zhi-Ming Ma and Tie-Yan Liu. “Target Transfer Q-Learning and Its Convergence Analysis.” In submission.
 	
 	\item \textbf{Wang Yue}, Qi Meng, Wei Chen, Yuting Liu, Zhi-Ming Ma and Tie-Yan Liu.  "Positively Scale-Invariant Space for Recurrent Neural Networks with ReLU Activations." In submission.
 	
 	\item \textbf{Wang Yue}, Yuting Liu, Zhi-Ming Ma "The Scale-Invariant Space for Attention Layer in Neural  Network." In submission.
 \end{enumerate}



 




\section{\faHeartO\ 获奖情况}
\datedline{校级三好学生}{2016/12}
\datedline{国家奖学金}{2015/12}
\datedline{一等学业奖学金}{2012/12}
\datedline{国家奖学金}{2012/12}
% vspace
\section{\faUser\ 其他经历}
% increase linespacing [parsep=0.5ex]
%\begin{itemize}[parsep=0.5ex]
  \datedsubsection{\textbf{实习生}, 机器学习组， 微软亚洲研究院。 Mentor：\href{https://www.microsoft.com/en-us/research/people/tyliu/}{{\color{blue}Tie-Yan Liu}},
  	\href{https://www.microsoft.com/en-us/research/people/wche/}{{\color{blue}Wei Chen}}   }{08/2016 - 至今}
  \datedsubsection{\textbf{参加ACML AWRL'18会议，并做paper talk}， 北京交通大学 }{11/2018}
  \datedsubsection{\textbf{参加NIPS-2017会议，并做poster展示}，长滩，美国}{12/2017}
  \datedsubsection{\textbf{参加疾病影像遗传学项目}{\small,脑fMRI影像及全基因组数据的处理和分析,中科院/复旦大学}}{1/2015 - 4/2016}
%\end{itemize}
%  \datedsubsection{\textbf{实习生}, 机器学习组， 微软亚洲研究院 }{08/2016-至今}
%  \item GitHub: https://github.com/username
%  \item 语言: 英语 - 熟练(TOEFL xxx)
\section{\faInfo\ 技能}
% increase linespacing [parsep=0.5ex]
%\begin{itemize}[parsep=0.5ex]
   \textbf{语言：}  中文，英文\\
   \textbf{编程语言：}   python, R, matlab, latex, c++ \\
    \textbf{其他工具和框架：}  git, docker, bash, pytorch, tensorflow
%   \datedsubsection{\textbf{参加NIPS-2017会议，并做poster展示}}{12/2017}
%   \datedsubsection{\textbf{参加AWRL'18会议，并做paper talk}}{11/2018}

%% Reference
%\newpage
%\bibliographystyle{IEEETran}
%\bibliography{mycite}
\end{document}
